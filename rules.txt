1. Prompt Formula
Role → Goal → Details → Constraints → Output Format
Example: You are a compliance officer. Review the contract for GDPR violations. Highlight them in a table with columns: clause, issue,
fix. Use plain language.
2. Prompting Rules
• Be Specific → replace vague terms with measurable criteria.
• Break It Down → complex tasks into smaller sequential steps.
• Use Examples → show 1–2 perfect outputs to match style.
• Iterate → refine in steps, don’t expect perfection first try.
3. Context Engineering Rules
• Only Relevant Info → remove fluff; noise reduces accuracy.
• Chunk Large Inputs → split into semantic sections (2–4 paragraphs).
• Label Sources → e.g., [Report: Q1 Earnings] Revenue: …
• Preserve Structure → use headings/tables to guide output.
• Prime with Rules → define reasoning priorities up front.
• Stay Within Context Window → know model token limits.
4. Limitations
• Context Window Loss → older info drops if input too long.
• No True Understanding → predicts text, not truth.
• Sensitive to Wording → small changes can alter results.
• Hallucinations → add verification steps.
• Bias Inheritance → define neutrality explicitly.
5. Multi-LLM Call Guidelines
• Use when tasks have multiple stages, need verification, exceed context window, or require different models.
• Decompose the task → retrieval, cleaning, reasoning, formatting.
• Define clear input/output for each call, in machine-readable form.
• Validate outputs at each stage before moving to next.
• Preserve state → pass key data forward explicitly.
• Keep each call single-purpose and scope-limited.
Example Multi-Call Flow: Financial Analysis
• Call 1 – Chunk & Summarize → JSON { key_metrics, sentiment }
• Call 2 – Aggregate Summaries → consolidated profile
• Call 3 – Recommendation Logic → decision + reasoning
• Call 4 – Verification & Formatting → final clean report